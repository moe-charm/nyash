/*!
 * Nyash Parser - Rust Implementation
 * 
 * Pythonç‰ˆnyashc_v4.pyã®NyashParserã‚’Rustã§å®Œå…¨å†å®Ÿè£…
 * Tokenåˆ—ã‚’AST (Abstract Syntax Tree) ã«å¤‰æ›
 * 
 * TODO: ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°è¨ˆç”»
 * - expressions.rs: å¼ãƒ‘ãƒ¼ã‚µãƒ¼ (parse_expression, parse_or, parse_andç­‰)
 * - statements.rs: æ–‡ãƒ‘ãƒ¼ã‚µãƒ¼ (parse_statement, parse_if, parse_loopç­‰)
 * - declarations.rs: å®£è¨€ãƒ‘ãƒ¼ã‚µãƒ¼ (parse_box_declaration, parse_function_declarationç­‰)
 * - errors.rs: ã‚¨ãƒ©ãƒ¼å‹å®šç¾©ã¨ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
 */

// ã‚µãƒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å®£è¨€
mod common;
mod expressions;
mod statements;
mod declarations;
mod items;
// mod errors;

use common::ParserUtils;

use crate::tokenizer::{Token, TokenType, TokenizeError};
use crate::ast::{ASTNode, Span};
use std::collections::HashMap;
use thiserror::Error;

// ===== ğŸ”¥ Debug Macros =====

/// Infinite loop detection macro - must be called in every loop that advances tokens
/// Prevents parser from hanging due to token consumption bugs
/// Uses parser's debug_fuel field for centralized fuel management
#[macro_export]
macro_rules! must_advance {
    ($parser:expr, $fuel:expr, $location:literal) => {
        // ãƒ‡ãƒãƒƒã‚°ç‡ƒæ–™ãŒSomeã®å ´åˆã®ã¿åˆ¶é™ãƒã‚§ãƒƒã‚¯
        if let Some(ref mut limit) = $parser.debug_fuel {
            if *limit == 0 {
                eprintln!("ğŸš¨ PARSER INFINITE LOOP DETECTED at {}", $location);
                eprintln!("ğŸ” Current token: {:?} at line {}", $parser.current_token().token_type, $parser.current_token().line);
                eprintln!("ğŸ” Parser position: {}/{}", $parser.current, $parser.tokens.len());
                return Err($crate::parser::ParseError::InfiniteLoop { 
                    location: $location.to_string(),
                    token: $parser.current_token().token_type.clone(),
                    line: $parser.current_token().line,
                });
            }
            *limit -= 1;
        }
        // None ã®å ´åˆã¯ç„¡åˆ¶é™ãªã®ã§ãƒã‚§ãƒƒã‚¯ã—ãªã„
    };
}

/// Initialize debug fuel for loop monitoring
#[macro_export]
macro_rules! debug_fuel {
    () => {
        100_000 // Default: 100k iterations should be enough for any reasonable program
    };
}

// Two-phase parser structures are no longer needed - simplified to direct parsing

/// ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼
#[derive(Error, Debug)]
pub enum ParseError {
    #[error("Unexpected token {found:?}, expected {expected} at line {line}")]
    UnexpectedToken { found: TokenType, expected: String, line: usize },
    
    #[error("Unexpected end of file")]
    UnexpectedEOF,
    
    #[error("Invalid expression at line {line}")]
    InvalidExpression { line: usize },
    
    #[error("Invalid statement at line {line}")]
    InvalidStatement { line: usize },
    
    #[error("Circular dependency detected between static boxes: {cycle}")]
    CircularDependency { cycle: String },
    
    #[error("ğŸš¨ Infinite loop detected in parser at {location} - token: {token:?} at line {line}")]
    InfiniteLoop { location: String, token: TokenType, line: usize },
    
    #[error("ğŸ”¥ Transparency system removed: {suggestion} at line {line}")]
    TransparencySystemRemoved { suggestion: String, line: usize },
    
    #[error("Unsupported namespace '{name}' at line {line}. Only 'nyashstd' is supported in Phase 0.")]
    UnsupportedNamespace { name: String, line: usize },
    
    #[error("Expected identifier at line {line}")]
    ExpectedIdentifier { line: usize },
    
    #[error("Tokenize error: {0}")]
    TokenizeError(#[from] TokenizeError),
}

/// Nyashãƒ‘ãƒ¼ã‚µãƒ¼ - ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã‚’ASTã«å¤‰æ›
pub struct NyashParser {
    pub(super) tokens: Vec<Token>,
    pub(super) current: usize,
    /// ğŸ”¥ Static boxä¾å­˜é–¢ä¿‚è¿½è·¡ï¼ˆå¾ªç’°ä¾å­˜æ¤œå‡ºç”¨ï¼‰
    pub(super) static_box_dependencies: std::collections::HashMap<String, std::collections::HashSet<String>>,
    /// ğŸ”¥ ãƒ‡ãƒãƒƒã‚°ç‡ƒæ–™ï¼šç„¡é™ãƒ«ãƒ¼ãƒ—æ¤œå‡ºç”¨åˆ¶é™å€¤ (None = ç„¡åˆ¶é™)
    pub(super) debug_fuel: Option<usize>,
}

// Implement ParserUtils trait
impl ParserUtils for NyashParser {
    fn tokens(&self) -> &Vec<Token> {
        &self.tokens
    }
    
    fn current(&self) -> usize {
        self.current
    }
    
    fn current_mut(&mut self) -> &mut usize {
        &mut self.current
    }
}

impl NyashParser {
    /// æ–°ã—ã„ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ä½œæˆ
    pub fn new(tokens: Vec<Token>) -> Self {
        Self {
            tokens,
            current: 0,
            static_box_dependencies: std::collections::HashMap::new(),
            debug_fuel: Some(100_000), // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        }
    }
    
    /// æ–‡å­—åˆ—ã‹ã‚‰ãƒ‘ãƒ¼ã‚¹ (ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚º + ãƒ‘ãƒ¼ã‚¹)
    pub fn parse_from_string(input: impl Into<String>) -> Result<ASTNode, ParseError> {
        Self::parse_from_string_with_fuel(input, Some(100_000))
    }
    
    /// æ–‡å­—åˆ—ã‹ã‚‰ãƒ‘ãƒ¼ã‚¹ (ãƒ‡ãƒãƒƒã‚°ç‡ƒæ–™æŒ‡å®šç‰ˆ)
    /// fuel: Some(n) = nå›ã¾ã§ã€None = ç„¡åˆ¶é™
    pub fn parse_from_string_with_fuel(input: impl Into<String>, fuel: Option<usize>) -> Result<ASTNode, ParseError> {
        let mut tokenizer = crate::tokenizer::NyashTokenizer::new(input);
        let tokens = tokenizer.tokenize()?;
        
        let mut parser = Self::new(tokens);
        parser.debug_fuel = fuel;
        let result = parser.parse();
        result
    }
    
    /// ãƒ‘ãƒ¼ã‚¹å®Ÿè¡Œ - Program ASTã‚’è¿”ã™
    pub fn parse(&mut self) -> Result<ASTNode, ParseError> {
        self.parse_program()
    }
    
    // ===== ãƒ‘ãƒ¼ã‚¹é–¢æ•°ç¾¤ =====
    
    /// ãƒ—ãƒ­ã‚°ãƒ©ãƒ å…¨ä½“ã‚’ãƒ‘ãƒ¼ã‚¹
    fn parse_program(&mut self) -> Result<ASTNode, ParseError> {
        let mut statements = Vec::new();
        let mut statement_count = 0;
        
        while !self.is_at_end() {
            
            // EOF tokenã¯ã‚¹ã‚­ãƒƒãƒ—
            if matches!(self.current_token().token_type, TokenType::EOF) {
                break;
            }
            
            // NEWLINE tokenã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ–‡ã®åŒºåˆ‡ã‚Šã¨ã—ã¦ä½¿ç”¨ï¼‰
            if matches!(self.current_token().token_type, TokenType::NEWLINE) {
                self.advance();
                continue;
            }
            
            let statement = self.parse_statement()?;
            statements.push(statement);
            statement_count += 1;
        }
        
        
        // ğŸ”¥ ã™ã¹ã¦ã®static boxè§£æå¾Œã«å¾ªç’°ä¾å­˜æ¤œå‡º
        self.check_circular_dependencies()?;
        
        Ok(ASTNode::Program { statements, span: Span::unknown() })
    }
    // Statement parsing methods are now in statements.rs module
    
    /// ä»£å…¥æ–‡ã¾ãŸã¯é–¢æ•°å‘¼ã³å‡ºã—ã‚’ãƒ‘ãƒ¼ã‚¹
    fn parse_assignment_or_function_call(&mut self) -> Result<ASTNode, ParseError> {
        
        // ã¾ãšå·¦è¾ºã‚’å¼ã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹
        let expr = self.parse_expression()?;
        
        // æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒ = ãªã‚‰ä»£å…¥æ–‡
        if self.match_token(&TokenType::ASSIGN) {
            self.advance(); // consume '='
            let value = Box::new(self.parse_expression()?);
            
            // å·¦è¾ºãŒä»£å…¥å¯èƒ½ãªå½¢å¼ã‹ãƒã‚§ãƒƒã‚¯
            match &expr {
                ASTNode::Variable { .. } | 
                ASTNode::FieldAccess { .. } => {
                    Ok(ASTNode::Assignment {
                        target: Box::new(expr),
                        value,
                        span: Span::unknown(),
                    })
                }
                _ => {
                    let line = self.current_token().line;
                    Err(ParseError::InvalidStatement { line })
                }
            }
        } else {
            // ä»£å…¥æ–‡ã§ãªã‘ã‚Œã°å¼æ–‡ã¨ã—ã¦è¿”ã™
            Ok(expr)
        }
    }
    
    // Expression parsing methods are now in expressions.rs module
    // Utility methods are now in common.rs module via ParserUtils trait
    // Item parsing methods are now in items.rs module
    
    // ===== ğŸ”¥ Static Boxå¾ªç’°ä¾å­˜æ¤œå‡º =====
}
